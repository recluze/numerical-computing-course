{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "muslim-transaction",
   "metadata": {},
   "source": [
    "# Issues of Scale "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-transition",
   "metadata": {},
   "source": [
    "## HDF5 - The Why and How"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-outdoors",
   "metadata": {},
   "source": [
    "Since we're on the topic of limits, let's go ahead and take a look at a case study that is very often handy when doing data analysis, machine learning and all related areas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-bosnia",
   "metadata": {},
   "source": [
    "The issue we consider here is that of handling very large datasets that do not fit in memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-andrews",
   "metadata": {},
   "source": [
    "For instance, you may have a dataset that is 85GB large but you only have 32GB main memory in your system. You can let your OS handle the memory but that is going to be too inefficient as the OS has no \"understanding\" of the data. Instead, we use a library that can do the loading of data in an intelligent manner. We'll see HDF5 here for that. The python interface to this is called *h5py*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-alberta",
   "metadata": {},
   "source": [
    "Let's simulate creation of a large dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alternate-falls",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h5py\n",
      "  Downloading h5py-3.4.0.tar.gz (371 kB)\n",
      "\u001b[K     |████████████████████████████████| 371 kB 572 kB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.5 in /Users/nam/miniforge3/lib/python3.8/site-packages (from h5py) (1.20.2)\n",
      "Building wheels for collected packages: h5py\n",
      "  Building wheel for h5py (PEP 517) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /Users/nam/miniforge3/bin/python3.8 /Users/nam/miniforge3/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py build_wheel /var/folders/xk/r91vl3h16k5c5ct0q19s9mxw0000gn/T/tmpy2g5qnvg\n",
      "       cwd: /private/var/folders/xk/r91vl3h16k5c5ct0q19s9mxw0000gn/T/pip-install-h9n4u22o/h5py_390d17ac624646ce90757d3ebd6cd735\n",
      "  Complete output (71 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.macosx-11.0-arm64-3.8\n",
      "  creating build/lib.macosx-11.0-arm64-3.8/h5py\n",
      "  copying h5py/h5py_warnings.py -> build/lib.macosx-11.0-arm64-3.8/h5py\n",
      "  copying h5py/version.py -> build/lib.macosx-11.0-arm64-3.8/h5py\n",
      "  copying h5py/__init__.py -> build/lib.macosx-11.0-arm64-3.8/h5py\n",
      "  copying h5py/ipy_completer.py -> build/lib.macosx-11.0-arm64-3.8/h5py\n",
      "  creating build/lib.macosx-11.0-arm64-3.8/h5py/_hl\n",
      "  copying h5py/_hl/files.py -> build/lib.macosx-11.0-arm64-3.8/h5py/_hl\n",
      "  copying h5py/_hl/compat.py -> build/lib.macosx-11.0-arm64-3.8/h5py/_hl\n",
      "  copying h5py/_hl/__init__.py -> build/lib.macosx-11.0-arm64-3.8/h5py/_hl\n",
      "  copying h5py/_hl/selections.py -> build/lib.macosx-11.0-arm64-3.8/h5py/_hl\n",
      "  copying h5py/_hl/dataset.py -> build/lib.macosx-11.0-arm64-3.8/h5py/_hl\n",
      "  copying h5py/_hl/vds.py -> build/lib.macosx-11.0-arm64-3.8/h5py/_hl\n",
      "  copying h5py/_hl/selections2.py -> build/lib.macosx-11.0-arm64-3.8/h5py/_hl\n",
      "  copying h5py/_hl/group.py -> build/lib.macosx-11.0-arm64-3.8/h5py/_hl\n",
      "  copying h5py/_hl/datatype.py -> build/lib.macosx-11.0-arm64-3.8/h5py/_hl\n",
      "  copying h5py/_hl/attrs.py -> build/lib.macosx-11.0-arm64-3.8/h5py/_hl\n",
      "  copying h5py/_hl/dims.py -> build/lib.macosx-11.0-arm64-3.8/h5py/_hl\n",
      "  copying h5py/_hl/base.py -> build/lib.macosx-11.0-arm64-3.8/h5py/_hl\n",
      "  copying h5py/_hl/filters.py -> build/lib.macosx-11.0-arm64-3.8/h5py/_hl\n",
      "  creating build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_dimension_scales.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_attribute_create.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_file_image.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/conftest.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_h5d_direct_chunk.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_h5f.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_dataset_getitem.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_group.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_errors.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_dataset_swmr.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_slicing.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_h5pl.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_attrs.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/__init__.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_attrs_data.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_h5t.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_big_endian_file.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_h5p.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_dims_dimensionproxy.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_h5o.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_datatype.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/common.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_dataset.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_file.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_selections.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_dtype.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_h5.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_file2.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_completions.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_filters.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_base.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  copying h5py/tests/test_objects.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests\n",
      "  creating build/lib.macosx-11.0-arm64-3.8/h5py/tests/data_files\n",
      "  copying h5py/tests/data_files/__init__.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests/data_files\n",
      "  creating build/lib.macosx-11.0-arm64-3.8/h5py/tests/test_vds\n",
      "  copying h5py/tests/test_vds/test_highlevel_vds.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests/test_vds\n",
      "  copying h5py/tests/test_vds/test_virtual_source.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests/test_vds\n",
      "  copying h5py/tests/test_vds/__init__.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests/test_vds\n",
      "  copying h5py/tests/test_vds/test_lowlevel_vds.py -> build/lib.macosx-11.0-arm64-3.8/h5py/tests/test_vds\n",
      "  copying h5py/tests/data_files/vlen_string_s390x.h5 -> build/lib.macosx-11.0-arm64-3.8/h5py/tests/data_files\n",
      "  copying h5py/tests/data_files/vlen_string_dset_utc.h5 -> build/lib.macosx-11.0-arm64-3.8/h5py/tests/data_files\n",
      "  copying h5py/tests/data_files/vlen_string_dset.h5 -> build/lib.macosx-11.0-arm64-3.8/h5py/tests/data_files\n",
      "  running build_ext\n",
      "  Loading library to get build settings and version: libhdf5.dylib\n",
      "  error: Unable to load dependency HDF5, make sure HDF5 is installed properly\n",
      "  error: dlopen(libhdf5.dylib, 6): image not found\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for h5py\u001b[0m\n",
      "\u001b[?25hFailed to build h5py\n",
      "\u001b[31mERROR: Could not build wheels for h5py which use PEP 517 and cannot be installed directly\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#this will be our HDF5 file \n",
    "filename = 'data/test.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(10).reshape((5,2)), \n",
    "                      columns=['A', 'B'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-sunset",
   "metadata": {},
   "source": [
    "Output: \n",
    "\n",
    "<pre>\n",
    "   A  B\n",
    "0  0  1\n",
    "1  2  3\n",
    "2  4  5\n",
    "3  6  7\n",
    "4  8  9\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to HDF5\n",
    "df.to_hdf(filename, 'data', mode='w', format='table')\n",
    "\n",
    "del df    # allow df to be garbage collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Append more data\n",
    "df2 = pd.DataFrame(np.arange(10).reshape((5,2)) * 10, \n",
    "                   columns=['A', 'B'])\n",
    "\n",
    "\n",
    "# This is the important bit! Remove `append` to see the difference \n",
    "df2.to_hdf(filename, 'data', append=True)\n",
    "\n",
    "del df2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.read_hdf(filename, 'data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-desert",
   "metadata": {},
   "source": [
    "Output: \n",
    "\n",
    "<pre> \n",
    "    A   B\n",
    "0   0   1\n",
    "1   2   3\n",
    "2   4   5\n",
    "3   6   7\n",
    "4   8   9\n",
    "0   0  10\n",
    "1  20  30\n",
    "2  40  50\n",
    "3  60  70\n",
    "4  80  90\n",
    "</pre> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-bermuda",
   "metadata": {},
   "source": [
    "And that's all there is to it! Libraries such as TensorFlow and Keras support HDF5 directly so you won't have to worry about memory issues later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-equity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
