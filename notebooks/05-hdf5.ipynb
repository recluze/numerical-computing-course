{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "viral-inflation",
   "metadata": {},
   "source": [
    "# Issues of Scale "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-yugoslavia",
   "metadata": {},
   "source": [
    "## HDF5 - The Why and How"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-bridge",
   "metadata": {},
   "source": [
    "Since we're on the topic of limits, let's go ahead and take a look at a case study that is very often handy when doing data analysis, machine learning and all related areas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-puzzle",
   "metadata": {},
   "source": [
    "The issue we consider here is that of handling very large datasets that do not fit in memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-pulse",
   "metadata": {},
   "source": [
    "For instance, you may have a dataset that is 85GB large but you only have 32GB main memory in your system. You can let your OS handle the memory but that is going to be too inefficient as the OS has no \"understanding\" of the data. Instead, we use a library that can do the loading of data in an intelligent manner. We'll see HDF5 here for that. The python interface to this is called *h5py*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-plumbing",
   "metadata": {},
   "source": [
    "Let's simulate creation of a large dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#this will be our HDF5 file \n",
    "filename = 'data/test.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(10).reshape((5,2)), \n",
    "                      columns=['A', 'B'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-constant",
   "metadata": {},
   "source": [
    "Output: \n",
    "\n",
    "<pre>\n",
    "   A  B\n",
    "0  0  1\n",
    "1  2  3\n",
    "2  4  5\n",
    "3  6  7\n",
    "4  8  9\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to HDF5\n",
    "df.to_hdf(filename, 'data', mode='w', format='table')\n",
    "\n",
    "del df    # allow df to be garbage collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Append more data\n",
    "df2 = pd.DataFrame(np.arange(10).reshape((5,2)) * 10, \n",
    "                   columns=['A', 'B'])\n",
    "\n",
    "\n",
    "# This is the important bit! Remove `append` to see the difference \n",
    "df2.to_hdf(filename, 'data', append=True)\n",
    "\n",
    "del df2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.read_hdf(filename, 'data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-denial",
   "metadata": {},
   "source": [
    "Output: \n",
    "\n",
    "<pre> \n",
    "    A   B\n",
    "0   0   1\n",
    "1   2   3\n",
    "2   4   5\n",
    "3   6   7\n",
    "4   8   9\n",
    "0   0  10\n",
    "1  20  30\n",
    "2  40  50\n",
    "3  60  70\n",
    "4  80  90\n",
    "</pre> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-globe",
   "metadata": {},
   "source": [
    "And that's all there is to it! Libraries such as TensorFlow and Keras support HDF5 directly so you won't have to worry about memory issues later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-washer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
